{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'DecathlonDataset' from 'monai.apps' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32md:\\Files\\GitHub\\CSE4095-Transformers-Project\\UNETR.ipynb Cell 1\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Files/GitHub/CSE4095-Transformers-Project/UNETR.ipynb#W0sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Files/GitHub/CSE4095-Transformers-Project/UNETR.ipynb#W0sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmonai\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Files/GitHub/CSE4095-Transformers-Project/UNETR.ipynb#W0sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmonai\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapps\u001b[39;00m \u001b[39mimport\u001b[39;00m DecathlonDataset\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'DecathlonDataset' from 'monai.apps' (unknown location)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import monai\n",
    "\n",
    "from monai.apps import DecathlonDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import Dict, List\n",
    "\n",
    "def _compute_path(base_dir, element, check_path=False):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        base_dir: the base directory of the dataset.\n",
    "        element: file path(s) to append to directory.\n",
    "        check_path: if `True`, only compute when the result is an existing path.\n",
    "\n",
    "    Raises:\n",
    "        TypeError: When ``element`` contains a non ``str``.\n",
    "        TypeError: When ``element`` type is not in ``Union[list, str]``.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def _join_path(base_dir, item):\n",
    "        result = os.path.normpath(os.path.join(base_dir, item))\n",
    "        if check_path and not os.path.exists(result):\n",
    "            # if not an existing path, don't join with base dir\n",
    "            return f\"{item}\"\n",
    "        return f\"{result}\"\n",
    "\n",
    "    if isinstance(element, (str, os.PathLike)):\n",
    "        return _join_path(base_dir, element)\n",
    "    if isinstance(element, list):\n",
    "        for e in element:\n",
    "            if not isinstance(e, (str, os.PathLike)):\n",
    "                return element\n",
    "        return [_join_path(base_dir, e) for e in element]\n",
    "    return element\n",
    "\n",
    "def _append_paths(base_dir, is_segmentation: bool, items: List[Dict]) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        base_dir: the base directory of the dataset.\n",
    "        is_segmentation: whether the datalist is for segmentation task.\n",
    "        items: list of data items, each of which is a dict keyed by element names.\n",
    "\n",
    "    Raises:\n",
    "        TypeError: When ``items`` contains a non ``dict``.\n",
    "\n",
    "    \"\"\"\n",
    "    for item in items:\n",
    "        if not isinstance(item, dict):\n",
    "            raise TypeError(f\"Every item in items must be a dict but got {type(item).__name__}.\")\n",
    "        for k, v in item.items():\n",
    "            if k == \"image\" or is_segmentation and k == \"label\":\n",
    "                item[k] = _compute_path(base_dir, v, check_path=False)\n",
    "            else:\n",
    "                # for other items, auto detect whether it's a valid path\n",
    "                item[k] = _compute_path(base_dir, v, check_path=True)\n",
    "    return items\n",
    "\n",
    "def load_decathlon_datalist(\n",
    "    data_list_file_path,\n",
    "    is_segmentation: bool = True,\n",
    "    data_list_key: str = \"training\",\n",
    "    base_dir = None,\n",
    ") -> List[Dict]:\n",
    "    \"\"\"Load image/label paths of decathlon challenge from JSON file\n",
    "\n",
    "    Json file is similar to what you get from http://medicaldecathlon.com/\n",
    "    Those dataset.json files\n",
    "\n",
    "    Args:\n",
    "        data_list_file_path: the path to the json file of datalist.\n",
    "        is_segmentation: whether the datalist is for segmentation task, default is True.\n",
    "        data_list_key: the key to get a list of dictionary to be used, default is \"training\".\n",
    "        base_dir: the base directory of the dataset, if None, use the datalist directory.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: When ``data_list_file_path`` does not point to a file.\n",
    "        ValueError: When ``data_list_key`` is not specified in the data list file.\n",
    "\n",
    "    Returns a list of data items, each of which is a dict keyed by element names, for example:\n",
    "\n",
    "    .. code-block::\n",
    "\n",
    "        [\n",
    "            {'image': '/workspace/data/chest_19.nii.gz',  'label': 0},\n",
    "            {'image': '/workspace/data/chest_31.nii.gz',  'label': 1}\n",
    "        ]\n",
    "\n",
    "    \"\"\"\n",
    "    data_list_file_path = Path(data_list_file_path)\n",
    "    if not data_list_file_path.is_file():\n",
    "        raise ValueError(f\"Data list file {data_list_file_path} does not exist.\")\n",
    "    with open(data_list_file_path) as json_file:\n",
    "        json_data = json.load(json_file)\n",
    "    if data_list_key not in json_data:\n",
    "        raise ValueError(f'Data list {data_list_key} not specified in \"{data_list_file_path}\".')\n",
    "    expected_data = json_data[data_list_key]\n",
    "    if data_list_key == \"test\" and not isinstance(expected_data[0], dict):\n",
    "        # decathlon datalist may save the test images in a list directly instead of dict\n",
    "        expected_data = [{\"image\": i} for i in expected_data]\n",
    "\n",
    "    if base_dir is None:\n",
    "        base_dir = data_list_file_path.parent\n",
    "\n",
    "    return _append_paths(base_dir, is_segmentation, expected_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load brain_tumor_segment.model\n",
    "model = torch.load('brain_tumor_segment.model', map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = r\"D:\\Files\\GitHub\\CSE4095-Transformers-Project\\tmp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Activations' from 'monai.transforms' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32md:\\Files\\GitHub\\CSE4095-Transformers-Project\\UNETR.ipynb Cell 5\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Files/GitHub/CSE4095-Transformers-Project/UNETR.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmonai\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtransforms\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Files/GitHub/CSE4095-Transformers-Project/UNETR.ipynb#W3sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     Activations,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Files/GitHub/CSE4095-Transformers-Project/UNETR.ipynb#W3sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     Activationsd,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Files/GitHub/CSE4095-Transformers-Project/UNETR.ipynb#W3sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     AsDiscrete,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Files/GitHub/CSE4095-Transformers-Project/UNETR.ipynb#W3sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     AsDiscreted,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Files/GitHub/CSE4095-Transformers-Project/UNETR.ipynb#W3sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     Compose,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Files/GitHub/CSE4095-Transformers-Project/UNETR.ipynb#W3sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     Invertd,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Files/GitHub/CSE4095-Transformers-Project/UNETR.ipynb#W3sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     LoadImaged,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Files/GitHub/CSE4095-Transformers-Project/UNETR.ipynb#W3sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     MapTransform,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Files/GitHub/CSE4095-Transformers-Project/UNETR.ipynb#W3sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     NormalizeIntensityd,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Files/GitHub/CSE4095-Transformers-Project/UNETR.ipynb#W3sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     Orientationd,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Files/GitHub/CSE4095-Transformers-Project/UNETR.ipynb#W3sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     RandFlipd,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Files/GitHub/CSE4095-Transformers-Project/UNETR.ipynb#W3sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     RandScaleIntensityd,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Files/GitHub/CSE4095-Transformers-Project/UNETR.ipynb#W3sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     RandShiftIntensityd,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Files/GitHub/CSE4095-Transformers-Project/UNETR.ipynb#W3sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     RandSpatialCropd,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Files/GitHub/CSE4095-Transformers-Project/UNETR.ipynb#W3sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     Spacingd,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Files/GitHub/CSE4095-Transformers-Project/UNETR.ipynb#W3sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     EnsureTyped,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Files/GitHub/CSE4095-Transformers-Project/UNETR.ipynb#W3sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     EnsureChannelFirstd,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Files/GitHub/CSE4095-Transformers-Project/UNETR.ipynb#W3sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Files/GitHub/CSE4095-Transformers-Project/UNETR.ipynb#W3sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mConvertToMultiChannelBasedOnBratsClassesd\u001b[39;00m(MapTransform):\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Files/GitHub/CSE4095-Transformers-Project/UNETR.ipynb#W3sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Files/GitHub/CSE4095-Transformers-Project/UNETR.ipynb#W3sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39m    Convert labels to multi channels based on brats classes:\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Files/GitHub/CSE4095-Transformers-Project/UNETR.ipynb#W3sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39m    label 1 is the peritumoral edema\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Files/GitHub/CSE4095-Transformers-Project/UNETR.ipynb#W3sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m \n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Files/GitHub/CSE4095-Transformers-Project/UNETR.ipynb#W3sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'Activations' from 'monai.transforms' (unknown location)"
     ]
    }
   ],
   "source": [
    "from monai.transforms import (\n",
    "    Activations,\n",
    "    Activationsd,\n",
    "    AsDiscrete,\n",
    "    AsDiscreted,\n",
    "    Compose,\n",
    "    Invertd,\n",
    "    LoadImaged,\n",
    "    MapTransform,\n",
    "    NormalizeIntensityd,\n",
    "    Orientationd,\n",
    "    RandFlipd,\n",
    "    RandScaleIntensityd,\n",
    "    RandShiftIntensityd,\n",
    "    RandSpatialCropd,\n",
    "    Spacingd,\n",
    "    EnsureTyped,\n",
    "    EnsureChannelFirstd,\n",
    ")\n",
    "\n",
    "class ConvertToMultiChannelBasedOnBratsClassesd(MapTransform):\n",
    "    \"\"\"\n",
    "    Convert labels to multi channels based on brats classes:\n",
    "    label 1 is the peritumoral edema\n",
    "    label 2 is the GD-enhancing tumor\n",
    "    label 3 is the necrotic and non-enhancing tumor core\n",
    "    The possible classes are TC (Tumor core), WT (Whole tumor)\n",
    "    and ET (Enhancing tumor).\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __call__(self, data):\n",
    "        d = dict(data)\n",
    "        for key in self.keys:\n",
    "            result = []\n",
    "            # merge label 2 and label 3 to construct TC\n",
    "            result.append(torch.logical_or(d[key] == 2, d[key] == 3))\n",
    "            # merge labels 1, 2 and 3 to construct WT\n",
    "            result.append(torch.logical_or(torch.logical_or(d[key] == 2, d[key] == 3), d[key] == 1))\n",
    "            # label 2 is ET\n",
    "            result.append(d[key] == 2)\n",
    "            d[key] = torch.stack(result, axis=0).float()\n",
    "        return d\n",
    "\n",
    "train_transform = Compose(\n",
    "    [\n",
    "        # load 4 Nifti images and stack them together\n",
    "        LoadImaged(keys=[\"image\", \"label\"]),\n",
    "        EnsureChannelFirstd(keys=\"image\"),\n",
    "        EnsureTyped(keys=[\"image\", \"label\"]),\n",
    "        ConvertToMultiChannelBasedOnBratsClassesd(keys=\"label\"),\n",
    "        Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
    "        Spacingd(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            pixdim=(1.0, 1.0, 1.0),\n",
    "            mode=(\"bilinear\", \"nearest\"),\n",
    "        ),\n",
    "        RandSpatialCropd(keys=[\"image\", \"label\"], roi_size=[224, 224, 144], random_size=False),\n",
    "        RandFlipd(keys=[\"image\", \"label\"], prob=0.5, spatial_axis=0),\n",
    "        RandFlipd(keys=[\"image\", \"label\"], prob=0.5, spatial_axis=1),\n",
    "        RandFlipd(keys=[\"image\", \"label\"], prob=0.5, spatial_axis=2),\n",
    "        NormalizeIntensityd(keys=\"image\", nonzero=True, channel_wise=True),\n",
    "        RandScaleIntensityd(keys=\"image\", factors=0.1, prob=1.0),\n",
    "        RandShiftIntensityd(keys=\"image\", offsets=0.1, prob=1.0),\n",
    "    ]\n",
    ")\n",
    "val_transform = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"image\", \"label\"]),\n",
    "        EnsureChannelFirstd(keys=\"image\"),\n",
    "        EnsureTyped(keys=[\"image\", \"label\"]),\n",
    "        ConvertToMultiChannelBasedOnBratsClassesd(keys=\"label\"),\n",
    "        Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
    "        Spacingd(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            pixdim=(1.0, 1.0, 1.0),\n",
    "            mode=(\"bilinear\", \"nearest\"),\n",
    "        ),\n",
    "        NormalizeIntensityd(keys=\"image\", nonzero=True, channel_wise=True),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_decathlon_datalist' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\Files\\GitHub\\CSE4095-Transformers-Project\\UNETR.ipynb Cell 6\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Files/GitHub/CSE4095-Transformers-Project/UNETR.ipynb#W5sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m data_dir \u001b[39m=\u001b[39m \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mbrats2019\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mMICCAI_BraTS_2019_Data_Training\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Files/GitHub/CSE4095-Transformers-Project/UNETR.ipynb#W5sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m datalist_json \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(data_dir, \u001b[39m\"\u001b[39m\u001b[39mdataset.json\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Files/GitHub/CSE4095-Transformers-Project/UNETR.ipynb#W5sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m datalist \u001b[39m=\u001b[39m load_decathlon_datalist(datalist_json, \u001b[39mTrue\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mtraining\u001b[39m\u001b[39m\"\u001b[39m, base_dir\u001b[39m=\u001b[39mdata_dir)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'load_decathlon_datalist' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "data_dir = r\".\\brats2019\\MICCAI_BraTS_2019_Data_Training\"\n",
    "datalist_json = os.path.join(data_dir, \"dataset.json\")\n",
    "datalist = load_decathlon_datalist(datalist_json, True, \"training\", base_dir=data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections.abc\n",
    "\n",
    "from typing import IO, TYPE_CHECKING, Any, Callable, Dict, List, Optional, Sequence, Union\n",
    "\n",
    "from torch.utils.data import Dataset as _TorchDataset\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "import logging\n",
    "from abc import ABC, abstractmethod\n",
    "from typing import Any, Callable, Dict, Generator, Hashable, Iterable, List, Mapping, Optional, Tuple, TypeVar, Union\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from monai import transforms\n",
    "\n",
    "def str2bool(value: str | bool, default: bool = False, raise_exc: bool = True) -> bool:\n",
    "    \"\"\"\n",
    "    Convert a string to a boolean. Case insensitive.\n",
    "    True: yes, true, t, y, 1. False: no, false, f, n, 0.\n",
    "    Args:\n",
    "        value: string to be converted to a boolean. If value is a bool already, simply return it.\n",
    "        raise_exc: if value not in tuples of expected true or false inputs,\n",
    "            should we raise an exception? If not, return `default`.\n",
    "    Raises\n",
    "        ValueError: value not in tuples of expected true or false inputs and\n",
    "            `raise_exc` is `True`.\n",
    "    Useful with argparse, for example:\n",
    "        parser.add_argument(\"--convert\", default=False, type=str2bool)\n",
    "        python mycode.py --convert=True\n",
    "    \"\"\"\n",
    "\n",
    "    if isinstance(value, bool):\n",
    "        return value\n",
    "\n",
    "    true_set = (\"yes\", \"true\", \"t\", \"y\", \"1\")\n",
    "    false_set = (\"no\", \"false\", \"f\", \"n\", \"0\")\n",
    "\n",
    "    if isinstance(value, str):\n",
    "        value = value.lower()\n",
    "        if value in true_set:\n",
    "            return True\n",
    "        if value in false_set:\n",
    "            return False\n",
    "\n",
    "    if raise_exc:\n",
    "        raise ValueError(f\"Got \\\"{value}\\\", expected a value from: {', '.join(true_set + false_set)}\")\n",
    "    return default\n",
    "\n",
    "class MONAIEnvVars:\n",
    "    \"\"\"\n",
    "    Environment variables used by MONAI.\n",
    "    \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def data_dir() -> str | None:\n",
    "        return os.environ.get(\"MONAI_DATA_DIRECTORY\")\n",
    "\n",
    "    @staticmethod\n",
    "    def debug() -> bool:\n",
    "        val = os.environ.get(\"MONAI_DEBUG\", False)\n",
    "        return val if isinstance(val, bool) else str2bool(val)\n",
    "\n",
    "    @staticmethod\n",
    "    def doc_images() -> str | None:\n",
    "        return os.environ.get(\"MONAI_DOC_IMAGES\")\n",
    "\n",
    "def _apply_transform(\n",
    "    transform, parameters: Any, unpack_parameters: bool = False\n",
    "):\n",
    "    \"\"\"\n",
    "    Perform transformation `transform` with the provided parameters `parameters`.\n",
    "\n",
    "    If `parameters` is a tuple and `unpack_items` is True, each parameter of `parameters` is unpacked\n",
    "    as arguments to `transform`.\n",
    "    Otherwise `parameters` is considered as single argument to `transform`.\n",
    "\n",
    "    Args:\n",
    "        transform: a callable to be used to transform `data`.\n",
    "        parameters: parameters for the `transform`.\n",
    "        unpack_parameters: whether to unpack parameters for `transform`. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        ReturnType: The return type of `transform`.\n",
    "    \"\"\"\n",
    "    if isinstance(parameters, tuple) and unpack_parameters:\n",
    "        return transform(*parameters)\n",
    "\n",
    "    return transform(parameters)\n",
    "\n",
    "\n",
    "def apply_transform(\n",
    "    transform,\n",
    "    data: Any,\n",
    "    map_items: bool = True,\n",
    "    unpack_items: bool = False,\n",
    "    log_stats: bool = False,\n",
    "):\n",
    "    \"\"\"\n",
    "    Transform `data` with `transform`.\n",
    "\n",
    "    If `data` is a list or tuple and `map_data` is True, each item of `data` will be transformed\n",
    "    and this method returns a list of outcomes.\n",
    "    otherwise transform will be applied once with `data` as the argument.\n",
    "\n",
    "    Args:\n",
    "        transform: a callable to be used to transform `data`.\n",
    "        data: an object to be transformed.\n",
    "        map_items: whether to apply transform to each item in `data`,\n",
    "            if `data` is a list or tuple. Defaults to True.\n",
    "        unpack_items: whether to unpack parameters using `*`. Defaults to False.\n",
    "        log_stats: whether to log the detailed information of data and applied transform when error happened,\n",
    "            for NumPy array and PyTorch Tensor, log the data shape and value range,\n",
    "            for other metadata, log the values directly. default to `False`.\n",
    "\n",
    "    Raises:\n",
    "        Exception: When ``transform`` raises an exception.\n",
    "\n",
    "    Returns:\n",
    "        Union[List[ReturnType], ReturnType]: The return type of `transform` or a list thereof.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if isinstance(data, (list, tuple)) and map_items:\n",
    "            return [_apply_transform(transform, item, unpack_items) for item in data]\n",
    "        return _apply_transform(transform, data, unpack_items)\n",
    "    except Exception as e:\n",
    "        # if in debug mode, don't swallow exception so that the breakpoint\n",
    "        # appears where the exception was raised.\n",
    "        if MONAIEnvVars.debug():\n",
    "            raise\n",
    "        if log_stats and not isinstance(transform, transforms.compose.Compose):\n",
    "            # log the input data information of exact transform in the transform chain\n",
    "            datastats = transforms.utility.array.DataStats(data_shape=False, value_range=False)\n",
    "            logger = logging.getLogger(datastats._logger_name)\n",
    "            logger.info(f\"\\n=== Transform input info -- {type(transform).__name__} ===\")\n",
    "            if isinstance(data, (list, tuple)):\n",
    "                data = data[0]\n",
    "\n",
    "            def _log_stats(data, prefix: Optional[str] = \"Data\"):\n",
    "                if isinstance(data, (np.ndarray, torch.Tensor)):\n",
    "                    # log data type, shape, range for array\n",
    "                    datastats(img=data, data_shape=True, value_range=True, prefix=prefix)\n",
    "                else:\n",
    "                    # log data type and value for other metadata\n",
    "                    datastats(img=data, data_value=True, prefix=prefix)\n",
    "\n",
    "            if isinstance(data, dict):\n",
    "                for k, v in data.items():\n",
    "                    _log_stats(data=v, prefix=k)\n",
    "            else:\n",
    "                _log_stats(data=data)\n",
    "        raise RuntimeError(f\"applying transform {transform}\") from e\n",
    "\n",
    "\n",
    "class Dataset(_TorchDataset):\n",
    "    \"\"\"\n",
    "    A generic dataset with a length property and an optional callable data transform\n",
    "    when fetching a data sample.\n",
    "    If passing slicing indices, will return a PyTorch Subset, for example: `data: Subset = dataset[1:4]`,\n",
    "    for more details, please check: https://pytorch.org/docs/stable/data.html#torch.utils.data.Subset\n",
    "\n",
    "    For example, typical input data can be a list of dictionaries::\n",
    "\n",
    "        [{                            {                            {\n",
    "             'img': 'image1.nii.gz',      'img': 'image2.nii.gz',      'img': 'image3.nii.gz',\n",
    "             'seg': 'label1.nii.gz',      'seg': 'label2.nii.gz',      'seg': 'label3.nii.gz',\n",
    "             'extra': 123                 'extra': 456                 'extra': 789\n",
    "         },                           },                           }]\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data: Sequence, transform: Optional[Callable] = None) -> None:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data: input data to load and transform to generate dataset for model.\n",
    "            transform: a callable data transform on input data.\n",
    "\n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "        self.transform: Any = transform\n",
    "\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.data)\n",
    "\n",
    "    def _transform(self, index: int):\n",
    "        \"\"\"\n",
    "        Fetch single data item from `self.data`.\n",
    "        \"\"\"\n",
    "        data_i = self.data[index]\n",
    "        return apply_transform(self.transform, data_i) if self.transform is not None else data_i\n",
    "\n",
    "    def __getitem__(self, index: Union[int, slice, Sequence[int]]):\n",
    "        \"\"\"\n",
    "        Returns a `Subset` if `index` is a slice or Sequence, a data item otherwise.\n",
    "        \"\"\"\n",
    "        if isinstance(index, slice):\n",
    "            # dataset[:42]\n",
    "            start, stop, step = index.indices(len(self))\n",
    "            indices = range(start, stop, step)\n",
    "            return Subset(dataset=self, indices=indices)\n",
    "        if isinstance(index, collections.abc.Sequence):\n",
    "            # dataset[[1, 3, 4]]\n",
    "            return Subset(dataset=self, indices=index)\n",
    "        return self._transform(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'datalist' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\Files\\GitHub\\CSE4095-Transformers-Project\\UNETR.ipynb Cell 8\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Files/GitHub/CSE4095-Transformers-Project/UNETR.ipynb#X10sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m train_ds \u001b[39m=\u001b[39m Dataset(data\u001b[39m=\u001b[39mdatalist, transform\u001b[39m=\u001b[39mtrain_transform)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'datalist' is not defined"
     ]
    }
   ],
   "source": [
    "train_ds = Dataset(data=datalist, transform=train_transform)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
